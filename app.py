import json
import urllib.request
from PIL import Image
from wordcloud import WordCloud
import matplotlib.pyplot as plt
from janome.tokenizer import Tokenizer

import pandas as pd
import streamlit as st


def hide_style():
    hide_streamlit_style = """
                    <style>
                    div[data-testid="stToolbar"] {
                    visibility: hidden;
                    height: 0%;
                    position: fixed;
                    }
                    div[data-testid="stDecoration"] {
                    visibility: hidden;
                    height: 0%;
                    position: fixed;
                    }
                    div[data-testid="stStatusWidget"] {
                    visibility: hidden;
                    height: 0%;
                    position: fixed;
                    }
                    #MainMenu {
                    visibility: hidden;
                    height: 0%;
                    }
                    header {
                    visibility: hidden;
                    height: 0%;
                    }
                    footer {
                    visibility: hidden;
                    height: 0%;
                    }
                    .block-container {
                    padding-top: 2rem;
                    }
                    </style>
                    """
    st.markdown(hide_streamlit_style, unsafe_allow_html=True)

@st.cache_data(show_spinner=False)
def get_word_str(text):
    word_list=[]
    t = Tokenizer()
    for token in t.tokenize(text):
        split_token = token.part_of_speech.split(',')
        ## ä¸€èˆ¬åè©ã‚’æŠ½å‡º
        if split_token[0] == 'åè©' and split_token[1] == 'ä¸€èˆ¬':
            word_list.append(token.surface)
    split_text=" ".join(word_list)
    return split_text

@st.cache_data(experimental_allow_widgets=True,show_spinner=False)
def show_wordcloud(text):
    with st.spinner("Wordcloudä½œæˆä¸­ãƒ»ãƒ»ãƒ»"):
        # Create some sample text
        split_text = get_word_str(text)

        # Create and generate a word cloud image:
        wordcloud = WordCloud(font_path="ipaexg.ttf",background_color='white').generate(split_text)

        # Display the generated image:
        plt.imshow(wordcloud, interpolation='bilinear')
        plt.axis("off") 
        st.pyplot(plt)

# ã‚¯ã‚¨ãƒªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’çµ„ã¿ç«‹ã¦ã‚‹(1ãƒšãƒ¼ã‚¸100ä»¶å›ºå®š)
def prepare_parameter(query):
    params = {"per_page": "100"}
    if query is not None:
        params["query"] = query

    return params


# èªè¨¼ãƒˆãƒ¼ã‚¯ãƒ³ãŒæŒ‡å®šã•ã‚ŒãŸå ´åˆã«ãƒ˜ãƒƒãƒ€ã«ä»˜ä¸ã™ã‚‹
def prepare_headers(token):
    req_headers = {}
    if token is not None:
        req_headers = {"Authorization": "Bearer " + token}

    return req_headers

def create_metric(wch_colour_box=(87,204,0),wch_colour_font= (255,255,255),fontsize = 36,valign = "left",iconname="fas fa-asterisk",sline = "",value=""):
    
    lnk = '<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/all.min.css" crossorigin="anonymous">'

    htmlstr = f"""<p style='background-color: rgb({wch_colour_box[0]}, 
                                                {wch_colour_box[1]}, 
                                                {wch_colour_box[2]}, 1); 
                            color: rgb({wch_colour_font[0]}, 
                                    {wch_colour_font[1]}, 
                                    {wch_colour_font[2]}, 1); 
                            font-size: {fontsize}px; 
                            border-radius: 7px; 
                            padding-left: 12px; 
                            padding-top: 18px; 
                            padding-bottom: 18px; 
                            line-height:25px;'>
                            <i class='{iconname} fa-xs'></i> {value}
                            <BR><span style='font-size: 14px; 
                            margin-top: 0;'>{sline}</style></span>
                            </style></p>"""

    st.markdown(lnk + htmlstr, unsafe_allow_html=True)

def show_articles(value):
    create_metric(sline = "Articles",value=value,iconname="fa fa-newspaper")

def show_view_total(value):
    create_metric(sline = "Views",value=value,iconname="fa fa-eye")

def show_likes_total(value):
    create_metric(sline = "Likes",value=value,iconname="fa fa-thumbs-up")

def show_stocks_total(value):
    create_metric(sline = "Stocks",value=value,iconname="fa fa-bookmark")

def show_comments_total(value):
    create_metric(sline = "Comments",value=value,iconname="fa fa-comment")

@st.cache_data(show_spinner=False)
def pagenation_by_total_likes(item_ids,token=None, query=None):
    df_likes = pd.DataFrame()
    # ã‚¯ã‚¨ãƒªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æº–å‚™
    params = prepare_parameter(query)
    # ã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³ãŒæŒ‡å®šã•ã‚ŒãŸå ´åˆã«ä»˜ä¸
    req_headers = prepare_headers(token)

    for num,item_id in enumerate(item_ids):
        with st.spinner(f"è¨˜äº‹ã”ã¨ã®æƒ…å ±ã‚’å–å¾—ä¸­ï¼š{num+1}/{len(item_ids)}"):
            for page_num_likes in range(1, 101):
                params["page"] = str(page_num_likes)
                url_likes = (
                    f"https://qiita.com/api/v2/items/{item_id}/likes?"
                    + urllib.parse.urlencode(params)
                )

                req_likes = urllib.request.Request(url_likes, headers=req_headers)
                
                with urllib.request.urlopen(req_likes) as res_likes:
                    # DataFrameã«è¨˜äº‹æƒ…å ±ã‚’æ ¼ç´
                    df = pd.json_normalize(json.load(res_likes))
                    df["id"] = item_id
                    df_likes = pd.concat([df_likes, df])
                    print("Page: " + str(page_num_likes))
                    # Total-Countãƒ˜ãƒƒãƒ€ã®å€¤ã‹ã‚‰æœ€å¾Œã®ãƒšãƒ¼ã‚¸ã¾ã§å–å¾—ã—ãŸã‹ã‚’åˆ¤æ–­
                    total_count_likes = int(res_likes.headers["Total-Count"])
                    if page_num_likes >= (total_count_likes + 99) // 100:
                        break
    return df_likes

@st.cache_data(show_spinner=False)
def pagenation_by_total_count(token=None, query=None):
    df_ret = pd.DataFrame()
    
    # ã‚¯ã‚¨ãƒªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æº–å‚™
    params = prepare_parameter(query)
    # ã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³ãŒæŒ‡å®šã•ã‚ŒãŸå ´åˆã«ä»˜ä¸
    req_headers = prepare_headers(token)

    for page_num in range(1, 101):
        with st.spinner(f"è¨˜äº‹æƒ…å ±å–å¾—ä¸­ï¼š{page_num}"):
            params["page"] = str(page_num)
            url = "https://qiita.com/api/v2/items?" + urllib.parse.urlencode(params)

            req = urllib.request.Request(url, headers=req_headers)
            with urllib.request.urlopen(req) as res:
                body = json.load(res)
                # DataFrameã«è¨˜äº‹æƒ…å ±ã‚’æ ¼ç´
                df = pd.json_normalize(body)
                df_ret = pd.concat([df_ret, df])
                print("Page: " + str(page_num))
                # Total-Countãƒ˜ãƒƒãƒ€ã®å€¤ã‹ã‚‰æœ€å¾Œã®ãƒšãƒ¼ã‚¸ã¾ã§å–å¾—ã—ãŸã‹ã‚’åˆ¤æ–­
                total_count = int(res.headers["Total-Count"])
                if page_num >= (total_count + 99) // 100:
                    break
    item_ids = df_ret["id"].to_list()
            
    return df_ret, item_ids

@st.cache_data(show_spinner=False)
def get_user_info(token,user_name):
    url = f"https://qiita.com/api/v2/users/{urllib.parse.quote(user_name)}"
    req_headers = prepare_headers(token)

    req = urllib.request.Request(url, headers=req_headers)
    try:
        with urllib.request.urlopen(req) as res:
            body = json.load(res)
    except urllib.error.HTTPError as err:
        st.error("ãƒ¦ãƒ¼ã‚¶æƒ…å ±ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
        st.stop()
    return body

def main():
    st.set_page_config(
        page_title="Qiiboard",
        page_icon=Image.open('favicon.png'),
        layout="wide"
    )
    hide_style()
    # accsess_token = st.secrets["Qiita_API_KEY"]
    sort_options = {
        "ğŸ“ä½œæˆæ—¥": "created_at",
        "ğŸ‘ã„ã„ã­æ•°": "likes_count",
        "ğŸ“šã‚¹ãƒˆãƒƒã‚¯æ•°": "stocks_count",
        "ğŸ‘€é–²è¦§æ•°": "page_views_count",
        "ğŸ’¬ã‚³ãƒ¡ãƒ³ãƒˆæ•°": "comments_count",
    }
    with st.sidebar:   
        with st.form("info"):
            accsess_token = st.text_input("Access Token",placeholder="YOUR ACCESS TOKEN")
            user_name = st.text_input("User Name",placeholder="Qiita User Name")
            st.form_submit_button("ãƒ‡ãƒ¼ã‚¿å–å¾—")
    
    st.image("logo.png")
    if all([user_name,accsess_token]):
        if user_info:=get_user_info(accsess_token,user_name):
            html = f"""
            <style>
            .avatar {{
            vertical-align: middle;
            width: 50px;
            height: 50px;
            border-radius: 50%;
            }}  
            </style>

            <h2>
            <a href="https://qiita.com/{user_name}"><img src="{user_info['profile_image_url']}" alt="Avatar" class="avatar"></a>
            {user_name}
            </h2>
            """
            
            st.write("---")
            st.write(html,unsafe_allow_html=True)
            # Total-Countãƒ˜ãƒƒãƒ€ã‚’åˆ©ç”¨ã—ã¦ã€ã€ŒQiitaAPIã€ã‚¿ã‚°ã®è¨˜äº‹ã‚’å–å¾—
            df_total_count, item_ids = pagenation_by_total_count(
                token=accsess_token, query=f"user:{user_name}"
            )
            df_total_count["created_at"] =pd.to_datetime(df_total_count["created_at"])
            df_total_count["created_at"] =df_total_count["created_at"].dt.strftime('%Y/%m/%d %H:%M:%S')
            body_list = df_total_count["body"].to_list()
            title_list = df_total_count["title"].to_list()

            word_list = body_list+title_list
            wordcloud_text="".join(word_list)

            articles = f'{len(df_total_count):,}'
            view_total=f'{df_total_count["page_views_count"].sum():,}'
            likes_total=f'{df_total_count["likes_count"].sum():,}'
            stocks_total=f'{df_total_count["stocks_count"].sum():,}'
            comments_total=f'{df_total_count["comments_count"].sum():,}'

            cols=st.columns(5)
            with cols[0]:
                show_articles(articles)
            with cols[1]:
                show_view_total(view_total)
            with cols[2]:
                show_likes_total(likes_total)
            with cols[3]:
                show_stocks_total(stocks_total)
            with cols[4]:
                show_comments_total(comments_total)

            show_wordcloud(wordcloud_text)

            if st.button("è¨˜äº‹ã”ã¨ã®æƒ…å ±ã‚’å–å¾—ã™ã‚‹",help="å–å¾—ã«æ™‚é–“ãŒã‹ã‹ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™ã€‚"):
                df_likes = pagenation_by_total_likes(
                token=accsess_token, query=f"user:{user_name}",item_ids=item_ids
            )
                st.write("## Details")
                sort_value_jp = st.selectbox("Sort", options=sort_options.keys())
                if len(df_likes):
                    df_likes["created_at"]=df_likes["created_at"].str[0:13]+":00:00"
                    df_likes["created_at"]=pd.to_datetime(df_likes["created_at"])
                    df_likes["created_at"]=df_likes["created_at"].dt.strftime('%Y/%m/%d')


                for id, sdf in df_total_count.sort_values(
                    sort_options[sort_value_jp], ascending=False
                ).groupby("id", sort=False):
                    likes=pd.DataFrame()

                    if len(df_likes):
                        likes = df_likes[df_likes["id"]==id][["created_at","id"]].groupby("created_at").count()
                        likes["likes"] = likes["id"].cumsum()
                        likes=likes.drop("id",axis=1)

                    title=sdf["title"].values[0]
                    title_caption = sdf[sort_options[sort_value_jp]].values[0]
                    with st.expander(f"ã€{sort_value_jp} / {title_caption}ã€‘\t{title} "):
                        st.write(f'<a href="{sdf["url"].values[0]}">{title}</a>',unsafe_allow_html=True)
                        cols=st.columns(4)
                        with cols[0]:
                            show_view_total(sdf["page_views_count"].values[0])
                        with cols[1]:
                            show_likes_total(sdf["likes_count"].values[0])
                        with cols[2]:
                            show_stocks_total(sdf["stocks_count"].values[0])
                        with cols[3]:
                            show_comments_total(sdf["comments_count"].values[0])
                        st.line_chart(likes)

    else:
        st.info("ã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³ã¨ãƒ¦ãƒ¼ã‚¶ãƒ¼åã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚\n\n[ã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³ã®å–å¾—æ–¹æ³•](https://github.com/ppspps824/Qiiboard)",icon="ğŸ‘ˆ")
            
if __name__ == "__main__":
    main()
